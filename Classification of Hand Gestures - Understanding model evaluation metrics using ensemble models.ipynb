{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dataset__:\n",
    "- Classification of hand gestures based on sensor recordings of muscle movements.\n",
    "- Data source:UCI\n",
    "\n",
    "__Project Goal__:\n",
    "1. Understanding various evaluation metrics used for classification\n",
    "2. Compare performance of different classification methods.\n",
    "\n",
    "__Methods Used__:\n",
    "1. [Accuracy](#accuracy), [Confusion matrix](#confusion_matrix), [Classification report](#precision)\n",
    "2. Logistic Regression, KNN, Gradient Boosted trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending file 1_raw_data_13-12_22.03.16.txt\n",
      "Appending file 2_raw_data_13-13_22.03.16.txt\n",
      "Appending file 1_raw_data_14-19_22.03.16.txt\n",
      "Appending file 2_raw_data_14-21_22.03.16.txt\n",
      "Appending file 1_raw_data_09-32_11.04.16.txt\n",
      "Appending file 2_raw_data_09-34_11.04.16.txt\n",
      "Appending file 1_raw_data_18-02_24.04.16.txt\n",
      "Appending file 2_raw_data_18-03_24.04.16.txt\n",
      "Appending file 1_raw_data_10-28_30.03.16.txt\n",
      "Appending file 2_raw_data_10-29_30.03.16.txt\n",
      "Appending file 1_raw_data_10-38_11.04.16.txt\n",
      "Appending file 2_raw_data_10-40_11.04.16.txt\n",
      "Appending file 1_raw_data_18-48_22.03.16.txt\n",
      "Appending file 2_raw_data_18-50_22.03.16.txt\n",
      "Appending file 1_raw_data_12-14_23.03.16.txt\n",
      "Appending file 2_raw_data_12-16_23.03.16.txt\n",
      "Appending file 1_raw_data_12-41_23.03.16.txt\n",
      "Appending file 2_raw_data_12-43_23.03.16.txt\n",
      "Appending file 1_raw_data_11-08_21.03.16.txt\n",
      "Appending file 2_raw_data_11-10_21.03.16.txt\n",
      "Appending file 1_raw_data_13-11_18.03.16.txt\n",
      "Appending file 2_raw_data_13-13_18.03.16.txt\n",
      "Appending file 1_raw_data_11-35_28.03.16.txt\n",
      "Appending file 2_raw_data_11-36_28.03.16.txt\n",
      "Appending file 1_raw_data_13-26_21.03.16.txt\n",
      "Appending file 2_raw_data_13-29_21.03.16.txt\n",
      "Appending file 1_raw_data_09-50_15.04.16.txt\n",
      "Appending file 2_raw_data_09-51_15.04.16.txt\n",
      "Appending file 1_raw_data_08-49_13.04.16.txt\n",
      "Appending file 2_raw_data_08-51_13.04.16.txt\n",
      "Appending file 1_raw_data_12-12_25.04.16.txt\n",
      "Appending file 2_raw_data_12-14_25.04.16.txt\n",
      "Appending file 1_raw_data_11-19_23.03.16.txt\n",
      "Appending file 2_raw_data_11-20_23.03.16.txt\n",
      "Appending file 1_raw_data_12-35_21.03.16.txt\n",
      "Appending file 2_raw_data_12-37_21.03.16.txt\n",
      "Appending file 1_raw_data_12-10_26.04.16.txt\n",
      "Appending file 2_raw_data_12-11_26.04.16.txt\n",
      "Appending file 1_raw_data_11-41_22.03.16.txt\n",
      "Appending file 2_raw_data_11-43_22.03.16.txt\n",
      "Appending file 1_raw_data_20-28_24.04.16.txt\n",
      "Appending file 2_raw_data_20-30_24.04.16.txt\n",
      "Appending file 1_raw_data_12-37_28.03.16.txt\n",
      "Appending file 2_raw_data_12-39_28.03.16.txt\n",
      "Appending file 1_raw_data_13-18_05.04.16.txt\n",
      "Appending file 2_raw_data_13-19_05.04.16.txt\n",
      "Appending file 1_raw_data_10-16_12.04.16.txt\n",
      "Appending file 2_raw_data_10-17_12.04.16.txt\n",
      "Appending file 1_raw_data_14-51_24.04.16.txt\n",
      "Appending file 2_raw_data_14-53_24.04.16.txt\n",
      "Appending file 1_raw_data_10-22_29.03.16.txt\n",
      "Appending file 2_raw_data_10-23_29.03.16.txt\n",
      "Appending file 1_raw_data_12-19_06.04.16.txt\n",
      "Appending file 2_raw_data_12-20_06.04.16.txt\n",
      "Appending file 1_raw_data_12-10_15.04.16.txt\n",
      "Appending file 2_raw_data_12-11_15.04.16.txt\n",
      "Appending file 1_raw_data_10-17_15.04.16.txt\n",
      "Appending file 2_raw_data_10-18_15.04.16.txt\n",
      "Appending file 1_raw_data_09-49_21.03.16.txt\n",
      "Appending file 2_raw_data_09-50_21.03.16.txt\n",
      "Appending file 1_raw_data_11-15_11.04.16.txt\n",
      "Appending file 2_raw_data_11-16_11.04.16.txt\n",
      "Appending file 1_raw_data_12-04_27.04.16.txt\n",
      "Appending file 2_raw_data_12-06_27.04.16.txt\n",
      "Appending file 1_raw_data_09-49_12.04.16.txt\n",
      "Appending file 2_raw_data_09-50_12.04.16.txt\n",
      "Appending file 1_raw_data_10-51_07.04.16.txt\n",
      "Appending file 2_raw_data_10-53_07.04.16.txt\n",
      "Appending file 1_raw_data_10-03_13.04.16.txt\n",
      "Appending file 2_raw_data_10-05_13.04.16.txt\n",
      "Appending file 1_raw_data_13-03_15.04.16.txt\n",
      "Appending file 2_raw_data_13-04_15.04.16.txt\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "for root,dirs,files in os.walk(r''):\n",
    "            for file in files:\n",
    "                if file != 'README.txt':\n",
    "                    data_read = pd.read_csv(os.path.join(root,file),sep='\\t',header=None,index_col=None,skiprows=1)\n",
    "                    print ('Appending file',file)\n",
    "                    data = pd.concat([data,data_read])\n",
    "                else:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00003</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00003</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0        1        2        3        4        5        6        7        8  \\\n",
       "0  1  0.00001 -0.00002 -0.00001 -0.00003  0.00000 -0.00001  0.00000 -0.00001   \n",
       "1  5  0.00001 -0.00002 -0.00001 -0.00003  0.00000 -0.00001  0.00000 -0.00001   \n",
       "2  6 -0.00001  0.00001  0.00002  0.00000  0.00001 -0.00002 -0.00001  0.00001   \n",
       "\n",
       "     9  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00003</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00003</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C1       C2       C3       C4       C5       C6       C7       C8  \\\n",
       "0  0.00001 -0.00002 -0.00001 -0.00003  0.00000 -0.00001  0.00000 -0.00001   \n",
       "1  0.00001 -0.00002 -0.00001 -0.00003  0.00000 -0.00001  0.00000 -0.00001   \n",
       "2 -0.00001  0.00001  0.00002  0.00000  0.00001 -0.00002 -0.00001  0.00001   \n",
       "3 -0.00001  0.00001  0.00002  0.00000  0.00001 -0.00002 -0.00001  0.00001   \n",
       "4 -0.00001  0.00001  0.00002  0.00000  0.00001 -0.00002 -0.00001  0.00001   \n",
       "\n",
       "   Class  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_main = data.iloc[:,1:].copy()\n",
    "cols=['C1','C2','C3','C4','C5','C6','C7','C8','Class']\n",
    "data_main.columns = cols\n",
    "data_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4237908, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_main.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture = {'0':'unmarked data',\n",
    "'1':'hand at rest', \n",
    "'2': 'hand clenched in a fist', \n",
    "'3' : 'wrist flexion',\n",
    "'4' : 'wrist extension',\n",
    "'5' : 'radial deviations',\n",
    "'6' : 'ulnar deviations',\n",
    "'7' : 'extended palm' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'unmarked data',\n",
       " '1': 'hand at rest',\n",
       " '2': 'hand clenched in a fist',\n",
       " '3': 'wrist flexion',\n",
       " '4': 'wrist extension',\n",
       " '5': 'radial deviations',\n",
       " '6': 'ulnar deviations',\n",
       " '7': 'extended palm'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gesture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since the gesture 7 was not tested on everybody and gesture 0 is unmarked, we will delete that gesture from our dataset.\n",
    "\n",
    "Another exercise that can be done in with this dataset is to classify the unmarked gestures. But since there is no validation set for that, we won't be able to score our classification.\n",
    "\n",
    "# Tasks for this dataset\n",
    "\n",
    "For now, we will consider the following exercises on this dataset:\n",
    "\n",
    "1) Try various multi-class classification algorithms Logistic regression and KNN \n",
    "\n",
    "2) Evaluate various scoring metrics for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = data_main[data_main['Class']==0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data_main.loc[~((data_main['Class'] == 0) | (data_main['Class'] == 7))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0    253009\n",
       "5.0    251733\n",
       "4.0    251570\n",
       "1.0    250055\n",
       "3.0    249494\n",
       "2.0    243193\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our final data set will be data_clean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data_clean.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00003</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00003</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00003</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00003</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C1       C2       C3       C4       C5       C6       C7       C8  \\\n",
       "0 -0.00001  0.00000 -0.00001  0.00000  0.00000 -0.00001 -0.00001  0.00001   \n",
       "1 -0.00001 -0.00002  0.00000 -0.00001 -0.00001 -0.00001 -0.00003 -0.00002   \n",
       "2 -0.00001 -0.00002  0.00000 -0.00001 -0.00001 -0.00001 -0.00003 -0.00002   \n",
       "3 -0.00001 -0.00002  0.00000 -0.00001 -0.00001 -0.00001 -0.00003 -0.00002   \n",
       "4 -0.00001 -0.00002  0.00000 -0.00001 -0.00001 -0.00001 -0.00003 -0.00002   \n",
       "\n",
       "   Class  \n",
       "0    1.0  \n",
       "1    1.0  \n",
       "2    1.0  \n",
       "3    1.0  \n",
       "4    1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot tables side by side\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "def multi_table(table_list):\n",
    "    ''' Acceps a list of IpyTable objects and returns a table which contains each IpyTable in a cell'''\n",
    "    return HTML(\n",
    "        '<table><tr style=\"background-color:white;\">' + \n",
    "        ''.join(['<td>' + table._repr_html_() + '</td>' for table in table_list]) +\n",
    "        '</tr></table>'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers\n",
    "\n",
    "\n",
    "\n",
    "- Logistic Regression<br>\n",
    "Don't know how logistic regression works? Refer to my article [here]() on how machine learning algorithms work.\n",
    "\n",
    "- KNN<br>\n",
    "Don't know how KNN works? Refer to my article [here]() on how machine learning algorithms work.\n",
    "\n",
    "# Ensemble methods:\n",
    "------------------------------\n",
    "- Gradient Boost<br>\n",
    "Don't know how gradient boosting works? Refer to my article [here]() on how machine learning algorithms work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample data\n",
    "sample_data = data_clean.groupby('Class',as_index=False,group_keys=False).apply(lambda x:x.sample(frac =1,random_state =1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0    253009\n",
       "5.0    251733\n",
       "4.0    251570\n",
       "1.0    250055\n",
       "3.0    249494\n",
       "2.0    243193\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split --> Scale the train --> transform test with same scaler\n",
    "#split the data\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(sample_data.iloc[:,:-1],sample_data.iloc[:,-1],test_size =0.2)\n",
    "\n",
    "#Scale\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler_1 = scaler.fit(x_train)\n",
    "\n",
    "#Transform test and train data by using scaler which is trained only on train data\n",
    "\n",
    "x_train_scaled = pd.DataFrame(scaler_1.transform(x_train),columns=x_train.columns,index=x_train.index)\n",
    "x_test_scaled = pd.DataFrame(scaler_1.transform(x_test),columns=x_test.columns,index=x_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use various metrics from sklearn.metrics module independently, or \n",
    "# use the classification report to compute it all together\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_class = LogisticRegression(multi_class='multinomial',solver='lbfgs').fit(x_train_scaled,np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_log = log_class.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gd_model = GradientBoostingClassifier(learning_rate=0.3).fit(x_train_scaled,np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__New learning__ : \n",
    "1. np.ravel - \n",
    "2. Gradient boosting is super slow. Justified by slow learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gd = gd_model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_mod = KNeighborsClassifier().fit(x_train_scaled,np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default k=5, i.e., 5 neigbors considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mod = knn_mod.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"accuracy\"></a>\n",
    "**Understanding the Metrics**\n",
    "\n",
    "1. Accuracy\n",
    "     \n",
    " The most commonly used metric is the accuracy of model. Accuracy is defined as the ratio of __correctly predicted labels__ to the __total number of predictions__. \n",
    "<br>\n",
    "\n",
    "    In case of binary classification, if 70 out of 100 predictions are made correctly, the accuracy is 70%. <br>Same is applied for the multi class classification, which is our case. We just sum up the total correctly predicted labels and divide it by the total predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression 0.18121416492390205\n",
      "gradient trees 0.6764928571666817\n",
      "KNN 0.9736800851202925\n"
     ]
    }
   ],
   "source": [
    "print(\"logistic regression\",metrics.accuracy_score(y_test,pred_log))\n",
    "print(\"gradient trees\",metrics.accuracy_score(y_test,pred_gd))\n",
    "print(\"KNN\",metrics.accuracy_score(y_test,pred_mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    - Logistic Regression: 18%\n",
    "    - Gradient Trees: 68%\n",
    "    - KNN: 97%\n",
    "\n",
    "   But, can we identify how many type of hand movements of type \"1\" were classified correctly?<br>Not just from one accuracy percentage. For such kind of knowledge, we use another metric which is called confusion matrix.\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"confusion_matrix\"></a>\n",
    "**Confusion Matrix**\n",
    "    \n",
    "  Scratching the surface of the classification model performance a little more, confusion matrix is helpful when we want to understand the model performance for each label being classified. As shown below, ![title](images/confusion_matrix.png) <br>the confusion matrix is described as a matrix of predicted number of labels vs the actual number of labels. This is particularly for binary classification, but a similar matrix can be formed for multi-class problems where on top we have the actual values and down side we have predicted values. \n",
    "\n",
    "This matrix allows us to have a clear picture on how good are the labels being predicted on indivual level. The other terms used in the table are:\n",
    "  - TP: True Positives -  TP are the number of data points which are actually positive and were correctly classified as positives.\n",
    "  - FP: False Positives - FP are the number of data points which are actually negative but were classified positive. \n",
    "  - TN: True Negatives - TN are the number of data points which are actually negatives and were correctly classified as negatives.\n",
    "  - FN: False Negatives - FN are the number of data points which are actually positive but were classified as negatives.\n",
    "\n",
    "Furthter, FP are also called as **Type 1 error** and FN as **Type 2 error**. These terms are usually used in healthcare industry during the testing of disease. <br><br>\n",
    "__Ideally__, we want the FP and FN to be 0, since that would mean that we correctly identified positives and negatives. But this is not usually the case. We always get some FP and FN. Depending on the business applications, the task then changes from improving the accuracy of the overall model to now reducing the FP or FN.<br> <br>\n",
    "     \n",
    "   __Disease detection test__<br>\n",
    "\n",
    "  - We don't want the test to fail (i.e., Predicted- Negative) in identifying a patient having the disease (Actual -Postive). Since if the test fails, we have a false negative. In case the test had tested a patient without the disease as positive, it would also mean that the test has failed, but this would be a false positive. \n",
    "  - In the medical industry, we can afford having a false positive because the healthy patient can under go extra tests and then eventually be identified as healthy. So the __cost of false positive__ is the cost of extra tests.\n",
    "  - But the same is not correct for a false negative error. A false negative would mean that the patient is healthy, which actually is not the case, and no extra tests are requires. So, the __cost of false negative__ might eventually be the patient's life.\n",
    "  - Thus, in case of disease detection, we want our false negative rate to be as low as possible.\n",
    "  \n",
    "__Traffic Light Violation Detection__:\n",
    " - Traffic light violation is recorded via the images and videos mounted nearby. Whenever a driver violates the traffic light, not only the driver is fined but is also allowed to challenge the violation in the court. \n",
    " - If the driver has no violations but is still fined, he will have to challenge it in the court. This would mean wastage of government resources due to a false positive classification.\n",
    " - In this case, we would like to reduce the FP. But, we cannot increase the FN since that would mean that the model is failing to identify the real violators. This problem would need a balance of FP and FN.\n",
    "<br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Confusion Matrix- Logistic Regression\n",
      "\n",
      " [[  546     4    63  5361  8240 36025]\n",
      " [ 3413  5354  4372 15362  5564 14569]\n",
      " [ 3903  2619  5925 14192  7366 15914]\n",
      " [ 9055  1039  3145 23333  3283 10431]\n",
      " [ 7653   419  4448 21371  4637 11568]\n",
      " [ 4937  2676  5705 18127  4657 14535]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n Confusion Matrix- Logistic Regression\\n\\n\",confusion_matrix(y_test,pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Confusion Matrix- Gradient Tree\n",
      "\n",
      " [[47558   111   524   133  1662   251]\n",
      " [  819 28859  5589  2854  4939  5574]\n",
      " [ 1895  3997 30925   845  3153  9104]\n",
      " [  857  2742   621 32610  9629  3827]\n",
      " [ 2309  2904  3488  7725 32388  1282]\n",
      " [  692  4591  8422  3912  2540 30480]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n Confusion Matrix- Gradient Tree\\n\\n\",confusion_matrix(y_test,pred_gd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Confusion Matrix-KNN\n",
      "\n",
      " [[49954    27    88    41   106    23]\n",
      " [   85 46909   496   313   358   473]\n",
      " [  144   362 48425    97   285   606]\n",
      " [   68   202    72 49067   605   272]\n",
      " [  195   243   275   726 48481   176]\n",
      " [   63   368   568   384   170 49084]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n Confusion Matrix-KNN\\n\\n\",confusion_matrix(y_test,pred_mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for Logistic Regression \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.02      0.01      0.01     50239\n",
      "         2.0       0.44      0.11      0.18     48634\n",
      "         3.0       0.25      0.12      0.16     49919\n",
      "         4.0       0.24      0.46      0.32     50286\n",
      "         5.0       0.14      0.09      0.11     50096\n",
      "         6.0       0.14      0.29      0.19     50637\n",
      "\n",
      "    accuracy                           0.18    299811\n",
      "   macro avg       0.20      0.18      0.16    299811\n",
      "weighted avg       0.20      0.18      0.16    299811\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for Logistic Regression \\n\\n\",classification_report(y_test,pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for Gradient Tree \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.88      0.95      0.91     50239\n",
      "         2.0       0.67      0.59      0.63     48634\n",
      "         3.0       0.62      0.62      0.62     49919\n",
      "         4.0       0.68      0.65      0.66     50286\n",
      "         5.0       0.60      0.65      0.62     50096\n",
      "         6.0       0.60      0.60      0.60     50637\n",
      "\n",
      "    accuracy                           0.68    299811\n",
      "   macro avg       0.67      0.68      0.67    299811\n",
      "weighted avg       0.67      0.68      0.67    299811\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for Gradient Tree \\n\\n\",classification_report(y_test,pred_gd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for KNN\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.99      0.99      0.99     50239\n",
      "         2.0       0.98      0.96      0.97     48634\n",
      "         3.0       0.97      0.97      0.97     49919\n",
      "         4.0       0.97      0.98      0.97     50286\n",
      "         5.0       0.97      0.97      0.97     50096\n",
      "         6.0       0.97      0.97      0.97     50637\n",
      "\n",
      "    accuracy                           0.97    299811\n",
      "   macro avg       0.97      0.97      0.97    299811\n",
      "weighted avg       0.97      0.97      0.97    299811\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for KNN\\n\\n\",classification_report(y_test,pred_mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"precision\"></a>\n",
    "\n",
    "**Understanding the Metrics**\n",
    "\n",
    "1. **Precision**<br><br>\n",
    "    Going a step forward with confusion matrix, we can determine the fractions between the numbers within the matrix for better understanding. Precision and recall are used not for the whole model, but when a specific label is of interest. __The precision of a model for a particular label is the proportion of the prediction which is correctly classified__.\n",
    "    <BR><br>Mathematically, precision is defined as:<br><br>\n",
    "    \\begin{equation}{\\text{Precision}}=\\frac{\\text { True Positive }}{\\text { True Positive }+\\text { False Positive }}\\end{equation}\n",
    "    \n",
    "   We can use precision to compare the algorithms:\n",
    "     - The precision of Logistic regression for label \"1.0\" is 2%.\n",
    "       This means that out of 50,239 predicted data points which have label \"1.0\",the algorithm correctly classified only 2% of data.\n",
    "     - Similarly, Gradient Tree was able to predict 88% of label \"1.0\" \n",
    "     - KNN predicted 99% of data with labal \"1.0\" correctly\n",
    "<br><br>\n",
    "\n",
    "2. **Recall**<br>\n",
    "      __Recall can be defined as the proportion of the true values for a particular label that our algorithm correctly classified__.<br> It is calculated as follows:<br><br>\n",
    "\\begin{equation}{\\text{Recall}}\n",
    "= \\frac{\\text { True Positive }}{\\text { True Positive }+\\text { False Negative }}\n",
    "\\end{equation} <br>\n",
    "Comparing the algorithms using recall:\n",
    "     - Out of 50,239 true label points of \"1.0\", only 1% were classified as \"1.0\".\n",
    "     - Gradient tree has recall of 95% for label 1.0. i.e, it classified 95% of the true labeled points.\n",
    "     - KNN has recall of 99% for label 1.0. \n",
    "     <br><Br>\n",
    "    \n",
    "3. **F1-Score**<br>\n",
    "    We now know that the recall as well as precision needs to be maximum for a good model. Doing both the metrics together might be a difficult task. To solve this issue, there is another metric called the F-1 Score. F-1 score is the harmonic mean of precision and recall. It is defined as:\n",
    "<br><Br>\\begin{equation}\n",
    "F_{1}=2 \\cdot \\frac{\\text { precision } \\cdot \\text { recall }}{\\text { precision }+\\text { recall }}\n",
    "\\end{equation}\n",
    "<br>\n",
    "The main advantage of F1-Score is that it is a single metric which helps in optimizing the other two metrics, precision and recall, which is more convienient.\n",
    "<bR><Br>\n",
    "    \n",
    "4. **Macro-Average & Weighted-average**: These are options that we can include for better use during imbalanced dataset or if we want to focus on some particular label. \n",
    "    - Macro-averages: This is the averaged unweighted mean of each label\n",
    "    - Weighted-mean: Average the support-weighted mean per label\n",
    "    - Micro-average: Averaging the total true positives,false negatives and false positives "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
